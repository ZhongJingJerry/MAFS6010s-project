{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZHONG JING 20654235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop a music recommendation model, after the feature engineering process, I mainly try three models Light GBM, TPOT autoML and adaboost. It turns out that Light GBM is the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13269\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\13269\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data include five datasets, train, test, members, songs and song_extra_info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"C:/Users/13269/Desktop/20 Spring Semester/MAFS6010S (L1) Machine Learning and its Applications/project/kkbox/data/\"\n",
    "\n",
    "## load data\n",
    "train = pd.read_csv(dataPath + 'train.csv', dtype={'msno' : 'category',\n",
    "                                                   'song_id' : 'category',\n",
    "                                                   'source_system_tab' : 'category',\n",
    "                                                   'source_screen_name' : 'category',\n",
    "                                                   'source_type' : 'category'})\n",
    "test = pd.read_csv(dataPath + 'test.csv', dtype={'msno' : 'category',\n",
    "                                                 'song_id' : 'category',\n",
    "                                                 'source_system_tab' : 'category',\n",
    "                                                 'source_screen_name' : 'category',\n",
    "                                                 'source_type' : 'category'})\n",
    "members = pd.read_csv(dataPath + 'members.csv', dtype={'msno' : 'category',\n",
    "                                                       'city' : 'category',\n",
    "                                                       #'bd' : np.uint8,\n",
    "                                                       'gender' : 'category',\n",
    "                                                       'registered_via' : 'category'},\n",
    "                      parse_dates=['registration_init_time', 'expiration_date'])\n",
    "songs = pd.read_csv(dataPath + 'songs.csv', dtype={'song_id' : 'category',\n",
    "                                                   'genre_ids': 'category',\n",
    "                                                   'artist_name' : 'category',\n",
    "                                                   'composer' : 'category',\n",
    "                                                   'lyricist' : 'category',\n",
    "                                                   'language' : 'category'})\n",
    "song_extra_info = pd.read_csv(dataPath + 'song_extra_info.csv', dtype={'song_id' : 'category'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since songs data are too large, to make the following data merge procedures faster, I only keep songs information that appear in the train or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter for song's information\n",
    "song_id = pd.concat([train.song_id, test.song_id]).unique()\n",
    "songs = songs[songs.song_id.isin(song_id)]\n",
    "song_extra_info = song_extra_info[song_extra_info.song_id.isin(song_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is an important procedure in modeling. In these datasets, I can derive some other deeper variables based on the original data. <br>\n",
    "For members data, membership_days can be derived from expiration_date and registration_init_time, also both expiration_date and registration_init_time can be splited into year, month and day variables to replace with the date variable. <br>\n",
    "For song_extra_info data, there is a isrc - International Standard Recording Code, which we can extract country code, registrant code and song_year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deal with members data\n",
    "members['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n",
    "members['registration_year'] = members['registration_init_time'].dt.year\n",
    "members['registration_month'] = members['registration_init_time'].dt.month\n",
    "members['registration_day'] = members['registration_init_time'].dt.day\n",
    "members['expiration_year'] = members['expiration_date'].dt.year\n",
    "members['expiration_month'] = members['expiration_date'].dt.month\n",
    "members['expiration_day'] = members['expiration_date'].dt.day\n",
    "members = members.drop(['registration_init_time','expiration_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deal with songs_extra data\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "song_extra_info['country_code'] = song_extra_info['isrc'].apply(lambda x: str(x)[0:2])\n",
    "song_extra_info['registrant_code'] = song_extra_info['isrc'].apply(lambda x: str(x)[2:5])\n",
    "song_extra_info['song_year'] = song_extra_info['isrc'].apply(isrc_to_year)\n",
    "song_extra_info.drop(['isrc', 'name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all these data with key of msno and song_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge data\n",
    "train = train.merge(members, on='msno', how='left')\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "train = train.merge(song_extra_info, on = 'song_id', how = 'left')\n",
    "\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(song_extra_info, on = 'song_id', how = 'left')\n",
    "\n",
    "## delete original data\n",
    "del members, songs, song_extra_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the string variables will be transform into categorical and interpolate missing value with level of 'no data'. For the numerical variables, missing data will be interpolate with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting object types to categorical\n",
    "factor_Y = 'target'\n",
    "factor_X = list(train.columns)\n",
    "factor_X.remove(factor_Y)\n",
    "#factor_process = list(set(factor_X).difference(['msno', 'song_id']))\n",
    "for col in factor_X:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        #test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deal with NA\n",
    "for col in factor_X:\n",
    "    # Replace NA for category\n",
    "    if str(train[col].dtype) == 'category':\n",
    "        train[col] = train[col].cat.add_categories(['no data'])\n",
    "        train[col].fillna('no data', inplace=True)\n",
    "        #test[col] = test[col].cat.add_categories(['no data'])\n",
    "        #test[col].fillna('no data', inplace=True)\n",
    "    # Replace NA for other\n",
    "    else:\n",
    "        train[col] = train[col].fillna(value=0)\n",
    "        #test[col] = test[col].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the original test dataset do not have the actual target, so we have no idea of the accuracy of prediction on test data. In this case I will separate 20% of train data as test data to test the performance of models and use the rest of data to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[factor_X], train[factor_Y], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data split, I take all information in the training dataset as known, and take all information in the testing dataset as unknown. Based on the known historical information, I can create more features in terms of users and songs. Variable song_count means the number of songs that every user has heared and variable msno_count means the number of users that have heared of this song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more features\n",
    "msno_song_count = X_train.groupby(['msno'])['song_id'].count().reset_index()\n",
    "msno_song_count.columns = ['msno', 'song_count']\n",
    "song_msno_count = X_train.groupby(['song_id'])['msno'].count().reset_index()\n",
    "song_msno_count.columns = ['song_id', 'msno_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I want to try some more features such as the most preferred genre category, artist, composer, lyricist and songs language of every single user. However the computation of these features are too time consuming... So I have to skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msno_genre_count = X_train.groupby(['msno','genre_ids']).count().reset_index()\n",
    "# msno_artist_count = X_train.groupby(['msno','artist_name']).count().reset_index()\n",
    "# msno_composer_count = X_train.groupby(['msno','composer']).count().reset_index()\n",
    "# msno_lyricist_count = X_train.groupby(['msno','lyricist']).count().reset_index()\n",
    "# msno_language_count = X_train.groupby(['msno','language']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge new features\n",
    "X_train = X_train.merge(msno_song_count, on='msno', how='left')\n",
    "X_train = X_train.merge(song_msno_count, on='song_id', how='left')\n",
    "X_test = X_test.merge(msno_song_count, on='msno', how='left')\n",
    "X_test = X_test.merge(song_msno_count, on='song_id', how='left')\n",
    "\n",
    "#test = test.merge(msno_song_count, on='msno', how='left')\n",
    "#test = test.merge(song_msno_count, on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## renew features\n",
    "factor_X = list(X_train.columns)\n",
    "#factor_X = list(set(factor_X).difference(['msno', 'song_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we have finished all the feature engineering part and get the final wide table for modeling. The following table shows the variables' type in our data, including 15 categorical and 12 numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5901934 entries, 0 to 5901933\n",
      "Data columns (total 27 columns):\n",
      "msno                  category\n",
      "song_id               category\n",
      "source_system_tab     category\n",
      "source_screen_name    category\n",
      "source_type           category\n",
      "city                  category\n",
      "bd                    int64\n",
      "gender                category\n",
      "registered_via        category\n",
      "membership_days       int32\n",
      "registration_year     int64\n",
      "registration_month    int64\n",
      "registration_day      int64\n",
      "expiration_year       int64\n",
      "expiration_month      int64\n",
      "expiration_day        int64\n",
      "song_length           float64\n",
      "genre_ids             category\n",
      "artist_name           category\n",
      "composer              category\n",
      "lyricist              category\n",
      "language              category\n",
      "country_code          category\n",
      "registrant_code       category\n",
      "song_year             float64\n",
      "song_count            int64\n",
      "msno_count            int64\n",
      "dtypes: category(15), float64(2), int32(1), int64(9)\n",
      "memory usage: 776.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1 Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try Light GBM model. Light GBM is a fast, distributed, high-performance gradient boosting framework. Unlike other boosting algorithms it splits the trees leafwise and not level wise. It trains faster(on larger datasets) compared to other boosting algorithms like XGBoost. It uses leaf wise splitting instead of level wise splitting. Leaf wise splitting may lead to overfitting. This can be avoided by specifying tree-specific hyper parameters like max depth. <br>\n",
    "To make training faster and avoid overfitting, I set learning to be 0.2, bagging_fraction to be 0.8, feature_fraction to be 0.8, num of leaves to be 100, iteration times to be 100. Here our metric is auc since it is a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_X_train, lgb_X_val, lgb_y_train, lgb_y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "lgb_train = lgb.Dataset(lgb_X_train, lgb_y_train)\n",
    "lgb_val = lgb.Dataset(lgb_X_val, lgb_y_val)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.2,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 100,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:668: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds.\n",
      "[5]\tvalid_0's auc: 0.744038\n",
      "[10]\tvalid_0's auc: 0.754057\n",
      "[15]\tvalid_0's auc: 0.76693\n",
      "[20]\tvalid_0's auc: 0.776095\n",
      "[25]\tvalid_0's auc: 0.781963\n",
      "[30]\tvalid_0's auc: 0.785361\n",
      "[35]\tvalid_0's auc: 0.788149\n",
      "[40]\tvalid_0's auc: 0.790025\n",
      "[45]\tvalid_0's auc: 0.79149\n",
      "[50]\tvalid_0's auc: 0.792436\n",
      "[55]\tvalid_0's auc: 0.792823\n",
      "[60]\tvalid_0's auc: 0.793624\n",
      "[65]\tvalid_0's auc: 0.794079\n",
      "[70]\tvalid_0's auc: 0.79504\n",
      "[75]\tvalid_0's auc: 0.795803\n",
      "[80]\tvalid_0's auc: 0.796061\n",
      "[85]\tvalid_0's auc: 0.796556\n",
      "[90]\tvalid_0's auc: 0.796902\n",
      "[95]\tvalid_0's auc: 0.797175\n",
      "[100]\tvalid_0's auc: 0.797395\n",
      "[105]\tvalid_0's auc: 0.797514\n",
      "[110]\tvalid_0's auc: 0.797812\n",
      "[115]\tvalid_0's auc: 0.798705\n",
      "[120]\tvalid_0's auc: 0.798955\n",
      "[125]\tvalid_0's auc: 0.799193\n",
      "[130]\tvalid_0's auc: 0.799551\n",
      "[135]\tvalid_0's auc: 0.799703\n",
      "[140]\tvalid_0's auc: 0.799863\n",
      "[145]\tvalid_0's auc: 0.800065\n",
      "[150]\tvalid_0's auc: 0.800177\n",
      "[155]\tvalid_0's auc: 0.800381\n",
      "[160]\tvalid_0's auc: 0.800573\n",
      "[165]\tvalid_0's auc: 0.800846\n",
      "[170]\tvalid_0's auc: 0.80098\n",
      "[175]\tvalid_0's auc: 0.801139\n",
      "[180]\tvalid_0's auc: 0.801307\n",
      "[185]\tvalid_0's auc: 0.801455\n",
      "[190]\tvalid_0's auc: 0.801538\n",
      "[195]\tvalid_0's auc: 0.801591\n",
      "[200]\tvalid_0's auc: 0.801734\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.801734\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = lgb.train(params, train_set = lgb_train, valid_sets = lgb_val, verbose_eval=5, early_stopping_rounds=5)\n",
    "#lgbm_model = lgb.train(params, train_set = lgb_train, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = lgbm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auc of prediction in test data is 0.8018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8018124860426501"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let me check for the feature importance, msno, artist_name and song_id are three most important variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msno</td>\n",
       "      <td>8010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>song_id</td>\n",
       "      <td>2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source_system_tab</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source_screen_name</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source_type</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>city</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bd</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>registered_via</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>membership_days</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>registration_year</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>registration_month</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>registration_day</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>expiration_year</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>expiration_month</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>expiration_day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>song_length</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>genre_ids</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>artist_name</td>\n",
       "      <td>4691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>composer</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lyricist</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>language</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>country_code</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>registrant_code</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>song_year</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>song_count</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>msno_count</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0     1\n",
       "0                 msno  8010\n",
       "1              song_id  2864\n",
       "2    source_system_tab    41\n",
       "3   source_screen_name   154\n",
       "4          source_type   126\n",
       "5                 city    27\n",
       "6                   bd     8\n",
       "7               gender     0\n",
       "8       registered_via    13\n",
       "9      membership_days    17\n",
       "10   registration_year    11\n",
       "11  registration_month     2\n",
       "12    registration_day     2\n",
       "13     expiration_year    19\n",
       "14    expiration_month     7\n",
       "15      expiration_day     1\n",
       "16         song_length     4\n",
       "17           genre_ids    87\n",
       "18         artist_name  4691\n",
       "19            composer  1357\n",
       "20            lyricist   684\n",
       "21            language     8\n",
       "22        country_code    10\n",
       "23     registrant_code  1400\n",
       "24           song_year     8\n",
       "25          song_count   118\n",
       "26          msno_count   131"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([lgbm_model.feature_name(), lgbm_model.feature_importance()]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another method to deal with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try other models, I have to deal with the categorical variables first. Here I use one hot encoder for some important categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for number of level in each categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno  30755\n",
      "song_id  359966\n",
      "source_system_tab  9\n",
      "source_screen_name  21\n",
      "source_type  13\n",
      "city  21\n",
      "gender  3\n",
      "registered_via  5\n",
      "genre_ids  573\n",
      "artist_name  40583\n",
      "composer  76065\n",
      "lyricist  33889\n",
      "language  11\n",
      "country_code  111\n",
      "registrant_code  6457\n"
     ]
    }
   ],
   "source": [
    "for i in list(train.select_dtypes(include=['category']).columns):\n",
    "    print(i + '  ' + str(len(train[i].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the former result and business sense, I choose 'source_type', 'gender', 'language' three variables to do one-hot-encoder. For the rest of  categorical variables, simply use numbers to replace with label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoder\n",
    "encoder = ce.OneHotEncoder(cols=['source_type','gender','language'],use_cat_names=True).fit(train)\n",
    "train2 = encoder.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge new features\n",
    "train2 = train2.merge(msno_song_count, on='msno', how='left')\n",
    "train2 = train2.merge(song_msno_count, on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical features\n",
    "for col in train2.select_dtypes(include=['category']).columns:\n",
    "    if col != 'msno ' and col != 'song_id ':\n",
    "        train2[col] = train2[col].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a series of data cleaning procedures, now we have 52 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7377418 entries, 0 to 7377417\n",
      "Data columns (total 52 columns):\n",
      "msno                                  int16\n",
      "song_id                               int32\n",
      "source_system_tab                     int8\n",
      "source_screen_name                    int8\n",
      "source_type_album                     int64\n",
      "source_type_artist                    int64\n",
      "source_type_listen-with               int64\n",
      "source_type_local-library             int64\n",
      "source_type_local-playlist            int64\n",
      "source_type_online-playlist           int64\n",
      "source_type_radio                     int64\n",
      "source_type_song                      int64\n",
      "source_type_song-based-playlist       int64\n",
      "source_type_top-hits-for-artist       int64\n",
      "source_type_topic-article-playlist    int64\n",
      "source_type_my-daily-playlist         int64\n",
      "source_type_no data                   int64\n",
      "target                                int64\n",
      "city                                  int8\n",
      "bd                                    int64\n",
      "gender_female                         int64\n",
      "gender_male                           int64\n",
      "gender_no data                        int64\n",
      "registered_via                        int8\n",
      "membership_days                       int32\n",
      "registration_year                     int64\n",
      "registration_month                    int64\n",
      "registration_day                      int64\n",
      "expiration_year                       int64\n",
      "expiration_month                      int64\n",
      "expiration_day                        int64\n",
      "song_length                           float64\n",
      "genre_ids                             int16\n",
      "artist_name                           int32\n",
      "composer                              int32\n",
      "lyricist                              int32\n",
      "language_-1.0                         int64\n",
      "language_10.0                         int64\n",
      "language_17.0                         int64\n",
      "language_24.0                         int64\n",
      "language_3.0                          int64\n",
      "language_31.0                         int64\n",
      "language_38.0                         int64\n",
      "language_45.0                         int64\n",
      "language_52.0                         int64\n",
      "language_59.0                         int64\n",
      "language_no data                      int64\n",
      "country_code                          int8\n",
      "registrant_code                       int16\n",
      "song_year                             float64\n",
      "song_count                            int64\n",
      "msno_count                            int64\n",
      "dtypes: float64(2), int16(3), int32(5), int64(37), int8(5)\n",
      "memory usage: 2.4 GB\n"
     ]
    }
   ],
   "source": [
    "train2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_Y = 'target'\n",
    "factor_X = list(train2.columns)\n",
    "factor_X.remove(factor_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I redo the data split again as the former split with random_state=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train2[factor_X], train2[factor_Y], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrain Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I retrain the Light GBM model with the same parameters to see which kind of data cleaning method is more suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_X_train, lgb_X_val, lgb_y_train, lgb_y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "lgb_train = lgb.Dataset(lgb_X_train, lgb_y_train)\n",
    "lgb_val = lgb.Dataset(lgb_X_val, lgb_y_val)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds.\n",
      "[5]\tvalid_0's auc: 0.738891\n",
      "[10]\tvalid_0's auc: 0.754711\n",
      "[15]\tvalid_0's auc: 0.767772\n",
      "[20]\tvalid_0's auc: 0.773389\n",
      "[25]\tvalid_0's auc: 0.780043\n",
      "[30]\tvalid_0's auc: 0.784037\n",
      "[35]\tvalid_0's auc: 0.786373\n",
      "[40]\tvalid_0's auc: 0.78863\n",
      "[45]\tvalid_0's auc: 0.790563\n",
      "[50]\tvalid_0's auc: 0.792077\n",
      "[55]\tvalid_0's auc: 0.793203\n",
      "[60]\tvalid_0's auc: 0.79386\n",
      "[65]\tvalid_0's auc: 0.794911\n",
      "[70]\tvalid_0's auc: 0.795807\n",
      "[75]\tvalid_0's auc: 0.796221\n",
      "[80]\tvalid_0's auc: 0.797006\n",
      "[85]\tvalid_0's auc: 0.797122\n",
      "[90]\tvalid_0's auc: 0.797985\n",
      "[95]\tvalid_0's auc: 0.798938\n",
      "[100]\tvalid_0's auc: 0.799303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's auc: 0.799314\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = lgb.train(params, train_set = lgb_train, valid_sets = lgb_val, verbose_eval=5, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auc of prediction in test data is 0.7990."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799091623828119"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = lgbm_model.predict(X_test)\n",
    "roc_auc_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let me check for the feature importance again, song_count, membership_days and msno are three most important variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msno</td>\n",
       "      <td>5160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>song_id</td>\n",
       "      <td>2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source_system_tab</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source_screen_name</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source_type_album</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>source_type_artist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>source_type_listen-with</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>source_type_local-library</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>source_type_local-playlist</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>source_type_online-playlist</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>source_type_radio</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>source_type_song</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>source_type_song-based-playlist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>source_type_top-hits-for-artist</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>source_type_topic-article-playlist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>source_type_my-daily-playlist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>source_type_no_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>city</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bd</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gender_female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gender_male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gender_no_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>registered_via</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>membership_days</td>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>registration_year</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>registration_month</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>registration_day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>expiration_year</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>expiration_month</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>expiration_day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>song_length</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>genre_ids</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>artist_name</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>composer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lyricist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>language_-1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>language_10.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>language_17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>language_24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>language_3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>language_31.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>language_38.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>language_45.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>language_52.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>language_59.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>language_no_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>country_code</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>registrant_code</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>song_year</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>song_count</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>msno_count</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0     1\n",
       "0                                 msno  5160\n",
       "1                              song_id  2027\n",
       "2                    source_system_tab    38\n",
       "3                   source_screen_name   139\n",
       "4                    source_type_album     5\n",
       "5                   source_type_artist     0\n",
       "6              source_type_listen-with     2\n",
       "7            source_type_local-library    14\n",
       "8           source_type_local-playlist    33\n",
       "9          source_type_online-playlist    16\n",
       "10                   source_type_radio     6\n",
       "11                    source_type_song     7\n",
       "12     source_type_song-based-playlist     1\n",
       "13     source_type_top-hits-for-artist     6\n",
       "14  source_type_topic-article-playlist     0\n",
       "15       source_type_my-daily-playlist     0\n",
       "16                 source_type_no_data     1\n",
       "17                                city    15\n",
       "18                                  bd    63\n",
       "19                       gender_female     0\n",
       "20                         gender_male     0\n",
       "21                      gender_no_data     0\n",
       "22                      registered_via     7\n",
       "23                     membership_days  1944\n",
       "24                   registration_year     8\n",
       "25                  registration_month     4\n",
       "26                    registration_day     0\n",
       "27                     expiration_year    13\n",
       "28                    expiration_month     3\n",
       "29                      expiration_day     0\n",
       "30                         song_length     5\n",
       "31                           genre_ids     5\n",
       "32                         artist_name    10\n",
       "33                            composer     0\n",
       "34                            lyricist     3\n",
       "35                       language_-1.0     7\n",
       "36                       language_10.0     2\n",
       "37                       language_17.0     0\n",
       "38                       language_24.0     0\n",
       "39                        language_3.0     3\n",
       "40                       language_31.0     5\n",
       "41                       language_38.0     0\n",
       "42                       language_45.0     0\n",
       "43                       language_52.0     2\n",
       "44                       language_59.0     2\n",
       "45                    language_no_data     0\n",
       "46                        country_code     1\n",
       "47                     registrant_code     4\n",
       "48                           song_year    12\n",
       "49                          song_count   110\n",
       "50                          msno_count   118"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([lgbm_model.feature_name(), lgbm_model.feature_importance()]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2 TPOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPOT stands for Tree-based Pipeline Optimization Tool. TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. Its modeling procedure is showed as follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](./tpot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPOT completes feature engineering, feature selection, model selection and parameter optimization automatedly. Here we set parameters generations=5, population_size=20, cv=5, max_time_mins=10 and then trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=20, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9.699088399999999 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: LogisticRegression(input_matrix, C=0.1, dual=False, penalty=l2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(generations=1000000, max_time_mins=5, population_size=20,\n",
       "               random_state=0, verbosity=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=5, population_size=20, cv=5, max_time_mins=5, verbosity=2, random_state=0)\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5623081767297738"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_tpot = tpot.predict(X_test)\n",
    "roc_auc_score(y_test, pred_test_tpot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 3 Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to train another boosting model to compare with the Light GBM. However the training of Adaboost on the whole dataset costs too much time, so here I only choose a subset(10%) of train data to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = X_train.sample(frac=0.1, random_state=0)\n",
    "y_train_s = y_train.sample(frac=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "adaboost.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6460334790006289"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_adaboost = adaboost.predict(X_test)\n",
    "roc_auc_score(y_test, pred_test_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I mainly try Light GBM in two different kind of data cleaning method, TPOT and other tree model like Adaboost and random forest. It turns out that Light GBM is the best one with auc 0.8018 and 0.7990 in the test data, which implies that these two method of data cleaning do not have too much difference for Light GBM in terms of auc performance. The training of TPOT takes a long time but only get a very bad peformance auc 0.5623. Both adaboost and random forest are not suitable for this problem since their training process cost too much time. Adaboost with 10% of training data only got 0.6460 auc on the test data, which is not good. Comparing to adaboost, Light GBM not only has a fast training speed, but also achieves a higher accuracy. <br>\n",
    "Finally, I can get the conclusion that Light GBM is quite a good model to deal with hugh dataset in a fast and accurate way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
